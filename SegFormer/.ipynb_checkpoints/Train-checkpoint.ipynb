{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e99048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests, zipfile, io\n",
    "\n",
    "def download_data():\n",
    "    url = \"https://www.dropbox.com/s/l1e45oht447053f/ADE20k_toy_dataset.zip?dl=1\"\n",
    "    r = requests.get(url)\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    z.extractall()\n",
    "\n",
    "download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fc098d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "load_entire_dataset = False\n",
    "\n",
    "if load_entire_dataset:\n",
    "    dataset = load_dataset(\"scene_parse_150\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f8fe1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class SemanticSegmentationDataset(Dataset):\n",
    "    \"\"\"Image (semantic) segmentation dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, feature_extractor, train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Root directory of the dataset containing the images + annotations.\n",
    "            feature_extractor (SegFormerFeatureExtractor): feature extractor to prepare images + segmentation maps.\n",
    "            train (bool): Whether to load \"training\" or \"validation\" images + annotations.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.train = train\n",
    "\n",
    "        sub_path = \"training\" if self.train else \"validation\"\n",
    "        self.img_dir = os.path.join(self.root_dir, \"images\", sub_path)\n",
    "        self.ann_dir = os.path.join(self.root_dir, \"annotations\", sub_path)\n",
    "        \n",
    "        # read images\n",
    "        image_file_names = []\n",
    "        for root, dirs, files in os.walk(self.img_dir):\n",
    "            image_file_names.extend(files)\n",
    "        self.images = sorted(image_file_names)\n",
    "        \n",
    "        # read annotations\n",
    "        annotation_file_names = []\n",
    "        for root, dirs, files in os.walk(self.ann_dir):\n",
    "            annotation_file_names.extend(files)\n",
    "        self.annotations = sorted(annotation_file_names)\n",
    "\n",
    "        assert len(self.images) == len(self.annotations), \"There must be as many images as there are segmentation maps\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = Image.open(os.path.join(self.img_dir, self.images[idx]))\n",
    "        segmentation_map = Image.open(os.path.join(self.ann_dir, self.annotations[idx]))\n",
    "\n",
    "        # randomly crop + pad both image and segmentation map to same size\n",
    "        encoded_inputs = self.feature_extractor(image, segmentation_map, return_tensors=\"pt\")\n",
    "\n",
    "        for k,v in encoded_inputs.items():\n",
    "            encoded_inputs[k].squeeze_() # remove batch dimension\n",
    "\n",
    "        return encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f67f89f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/models/segformer/feature_extraction_segformer.py:31: FutureWarning: The class SegformerFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use SegformerImageProcessor instead.\n",
      "  FutureWarning,\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/models/segformer/image_processing_segformer.py:105: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from transformers import SegformerFeatureExtractor\n",
    "\n",
    "root_dir = './ADE20k_toy_dataset'\n",
    "feature_extractor = SegformerFeatureExtractor(reduce_labels=True)\n",
    "\n",
    "train_dataset = SemanticSegmentationDataset(root_dir=root_dir, feature_extractor=feature_extractor)\n",
    "valid_dataset = SemanticSegmentationDataset(root_dir=root_dir, feature_extractor=feature_extractor, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f74c07e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 10\n",
      "Number of validation examples: 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6742ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values torch.Size([2, 3, 512, 512])\n",
      "labels torch.Size([2, 512, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 3, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "encoded_inputs = train_dataset[0]\n",
    "     \n",
    "encoded_inputs[\"pixel_values\"].shape\n",
    "     \n",
    "encoded_inputs[\"labels\"].shape\n",
    "     \n",
    "encoded_inputs[\"labels\"]\n",
    "     \n",
    "encoded_inputs[\"labels\"].squeeze().unique()\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=2)\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "     \n",
    "\n",
    "for k,v in batch.items():\n",
    "    print(k, v.shape)\n",
    "     \n",
    "\n",
    "batch[\"labels\"].shape\n",
    "\n",
    "mask = (batch[\"labels\"] != 255)\n",
    "mask\n",
    "\n",
    "\n",
    "\n",
    "batch[\"labels\"][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37ca76e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nvidia/mit-b0 were not used when initializing SegformerForSemanticSegmentation: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_fuse.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.1.proj.bias', 'decode_head.classifier.weight', 'decode_head.batch_norm.running_mean', 'decode_head.linear_c.3.proj.weight', 'decode_head.batch_norm.weight', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.linear_c.1.proj.weight', 'decode_head.batch_norm.running_var', 'decode_head.linear_c.2.proj.weight', 'decode_head.classifier.bias', 'decode_head.batch_norm.bias', 'decode_head.linear_c.3.proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:23: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f8910bb6ff4bef832f522c450923ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import SegformerForSemanticSegmentation\n",
    "import json\n",
    "from huggingface_hub import cached_download, hf_hub_url\n",
    "\n",
    "# load id2label mapping from a JSON on the hub\n",
    "# repo_id = \"datasets/huggingface/label-files\"\n",
    "filename = \"ade20k-id2label.json\"\n",
    "# id2label = json.load(open(cached_download(hf_hub_url(repo_id, filename)), \"r\"))\n",
    "id2label = json.load(open(filename, \"r\"))\n",
    "id2label = {int(k): v for k, v in id2label.items()}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "# define model\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/mit-b0\",\n",
    "                                                         num_labels=150, \n",
    "                                                         id2label=id2label, \n",
    "                                                         label2id=label2id,\n",
    ")\n",
    "\n",
    "\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"mean_iou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119d1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb60a46143e4f7e98cdaac7401c6fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/huggingface/modules/datasets_modules/metrics/mean_iou/d4add40cf977cdd73590b5873fa830f3f13adb678f6777a29fb07b7c81d14342/mean_iou.py:258: RuntimeWarning: invalid value encountered in true_divide\n",
      "  iou = total_area_intersect / total_area_union\n",
      "/root/.cache/huggingface/modules/datasets_modules/metrics/mean_iou/d4add40cf977cdd73590b5873fa830f3f13adb678f6777a29fb07b7c81d14342/mean_iou.py:259: RuntimeWarning: invalid value encountered in true_divide\n",
      "  acc = total_area_intersect / total_area_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.083634853363037\n",
      "Mean_iou: 0.000872726704809543\n",
      "Mean accuracy: 0.02625071979286301\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0acba680a74c1d842248b34508c3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.9570817947387695\n",
      "Mean_iou: 0.0020488594530478576\n",
      "Mean accuracy: 0.02228172344407478\n",
      "Epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8f2015e76b4644ab75c043fd7bbb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.785323143005371\n",
      "Mean_iou: 0.0063430898239593015\n",
      "Mean accuracy: 0.04676395855403611\n",
      "Epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed03ee6c9a0a431fb6ca0acd5d37c9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.602604866027832\n",
      "Mean_iou: 0.014031503001674968\n",
      "Mean accuracy: 0.10649824172317988\n",
      "Epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9c5d1f114f42869e8d1448885b0b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.463755130767822\n",
      "Mean_iou: 0.018681527606579894\n",
      "Mean accuracy: 0.12115054003402756\n",
      "Epoch: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7431bb95d64b1c8934cf72f18854eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.264898777008057\n",
      "Mean_iou: 0.03830783951840777\n",
      "Mean accuracy: 0.17892253403300518\n",
      "Epoch: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4f8b039f554f11a60a8417fb370fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.144379615783691\n",
      "Mean_iou: 0.04317706407551832\n",
      "Mean accuracy: 0.1700403152027156\n",
      "Epoch: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb456bddec8f43438e4c7d81bb5c4f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.1956071853637695\n",
      "Mean_iou: 0.04118160799578239\n",
      "Mean accuracy: 0.16185505252966206\n",
      "Epoch: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8740a6bc4154f33986dc8099a648188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.8265485763549805\n",
      "Mean_iou: 0.10915512843322746\n",
      "Mean accuracy: 0.2553750304089508\n",
      "Epoch: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1b43cc1dd945adbf9edfb21e4c0b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.9455580711364746\n",
      "Mean_iou: 0.05513144236416093\n",
      "Mean accuracy: 0.1903076201941269\n",
      "Epoch: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10fa272fc2ea4ff59df834b0bbc1a8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.9794440269470215\n",
      "Mean_iou: 0.0972939497069342\n",
      "Mean accuracy: 0.22521938509826214\n",
      "Epoch: 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba9f44469ca44fcae44c8aeb979d0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.5631840229034424\n",
      "Mean_iou: 0.12991140997449352\n",
      "Mean accuracy: 0.2031704879514114\n",
      "Epoch: 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b022c437ded14be9a7364cb20e43a101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.6403746604919434\n",
      "Mean_iou: 0.1588597536767722\n",
      "Mean accuracy: 0.2445338007389535\n",
      "Epoch: 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de781083e0b41cb973bf4edc9d6db33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.0155792236328125\n",
      "Mean_iou: 0.1764191782220241\n",
      "Mean accuracy: 0.25050622398015127\n",
      "Epoch: 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31eb866f0d0d4953ae1cf280dbebb12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.99212384223938\n",
      "Mean_iou: 0.16389293532289204\n",
      "Mean accuracy: 0.2699191512693911\n",
      "Epoch: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd629f4afe2d4f568e0932be56988930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.047090530395508\n",
      "Mean_iou: 0.20902907785865532\n",
      "Mean accuracy: 0.26924018558379786\n",
      "Epoch: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2a0cb19e124cababf8bae01f49c760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.8073089122772217\n",
      "Mean_iou: 0.23869955253160394\n",
      "Mean accuracy: 0.3124341089297942\n",
      "Epoch: 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d37bd1630f4217887b94f96722c6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.5908772945404053\n",
      "Mean_iou: 0.1771115542447049\n",
      "Mean accuracy: 0.23823296937920926\n",
      "Epoch: 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bdb681561f74eb4aaa3067d17e7c5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.375248670578003\n",
      "Mean_iou: 0.2169632421626907\n",
      "Mean accuracy: 0.29718072692124964\n",
      "Epoch: 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3284bd9ba8f041dd9c77f43424ae36dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.5620577335357666\n",
      "Mean_iou: 0.1991143184847925\n",
      "Mean accuracy: 0.25425310149786506\n",
      "Epoch: 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4cff3142ae444bb8c6ac9470b081417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.8127763271331787\n",
      "Mean_iou: 0.18012757905852955\n",
      "Mean accuracy: 0.24873413288410248\n",
      "Epoch: 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57a49f47bf3485e828b4769214e56ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.598235607147217\n",
      "Mean_iou: 0.23228515051820794\n",
      "Mean accuracy: 0.2792293507884741\n",
      "Epoch: 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c875b7949c5f499a93973d4ec6805bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.4259865283966064\n",
      "Mean_iou: 0.24344832399227115\n",
      "Mean accuracy: 0.30447836968262465\n",
      "Epoch: 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e70f62c9421495891c7c30482887be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.501638889312744\n",
      "Mean_iou: 0.19661824950280965\n",
      "Mean accuracy: 0.23714354054907186\n",
      "Epoch: 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637ed29936114b609ab239b67b9b1d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.688905715942383\n",
      "Mean_iou: 0.2277175576557373\n",
      "Mean accuracy: 0.272707188180831\n",
      "Epoch: 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85cc975daea46a6bb38756de07f00ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3967463970184326\n",
      "Mean_iou: 0.24239703511116592\n",
      "Mean accuracy: 0.30046512233539135\n",
      "Epoch: 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09392c1066a4f3085f4bf2caf9150e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.43829345703125\n",
      "Mean_iou: 0.29615899878556123\n",
      "Mean accuracy: 0.34215922629480217\n",
      "Epoch: 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b8f3ff7a1043e9bb53b0ce4f228165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.1405038833618164\n",
      "Mean_iou: 0.24143547877673488\n",
      "Mean accuracy: 0.2863028685084338\n",
      "Epoch: 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86834be9dc4540e3847875693c0bca31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3272511959075928\n",
      "Mean_iou: 0.25665873198636524\n",
      "Mean accuracy: 0.30161425344717985\n",
      "Epoch: 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f2b7c9263b47d0b01bde15d71c99af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.322385311126709\n",
      "Mean_iou: 0.2754421134240847\n",
      "Mean accuracy: 0.32687974575472695\n",
      "Epoch: 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea19a04294f4bb3be8f8e6c1ad03cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3545970916748047\n",
      "Mean_iou: 0.32393720417416194\n",
      "Mean accuracy: 0.3768557119365437\n",
      "Epoch: 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc1c2da4e0a4ee68bc42eb164d94c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.350829839706421\n",
      "Mean_iou: 0.22320799456963988\n",
      "Mean accuracy: 0.2735001358673426\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00006)\n",
    "# move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "    print(\"Epoch:\", epoch)\n",
    "    for idx, batch in enumerate(tqdm(train_dataloader)):\n",
    "        # get the inputs;\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss, logits = outputs.loss, outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # evaluate\n",
    "        with torch.no_grad():\n",
    "            upsampled_logits = nn.functional.interpolate(logits, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            predicted = upsampled_logits.argmax(dim=1)\n",
    "\n",
    "          # note that the metric expects predictions + labels as numpy arrays\n",
    "            metric.add_batch(predictions=predicted.detach().cpu().numpy(), references=labels.detach().cpu().numpy())\n",
    "\n",
    "        # let's print loss and metrics every 100 batches\n",
    "        if idx % 100 == 0:\n",
    "            metrics = metric.compute(num_labels=len(id2label), \n",
    "                                   ignore_index=255,\n",
    "                                   reduce_labels=False, # we've already reduced the labels before)\n",
    "            )\n",
    "\n",
    "            print(\"Loss:\", loss.item())\n",
    "            print(\"Mean_iou:\", metrics[\"mean_iou\"])\n",
    "            print(\"Mean accuracy:\", metrics[\"mean_accuracy\"])\n",
    "\n",
    "    torch.save(model, f\"./checkpoint/model_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e4212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3982597",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = Image.open('/content/ADE20k_toy_dataset/images/training/ADE_train_00000001.jpg')\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c916b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the image for the model\n",
    "encoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "pixel_values = encoding.pixel_values.to(device)\n",
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33b7f765",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21103/3989970923.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# logits are of shape (batch_size, num_labels, height/4, width/4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# forward pass\n",
    "outputs = model(pixel_values=pixel_values)\n",
    "\n",
    "# logits are of shape (batch_size, num_labels, height/4, width/4)\n",
    "logits = outputs.logits.cpu()\n",
    "print(logits.shape)\n",
    "\n",
    "def ade_palette():\n",
    "    \"\"\"ADE20K palette that maps each class to RGB values.\"\"\"\n",
    "    return [[120, 120, 120], [180, 120, 120], [6, 230, 230], [80, 50, 50],\n",
    "            [4, 200, 3], [120, 120, 80], [140, 140, 140], [204, 5, 255],\n",
    "            [230, 230, 230], [4, 250, 7], [224, 5, 255], [235, 255, 7],\n",
    "            [150, 5, 61], [120, 120, 70], [8, 255, 51], [255, 6, 82],\n",
    "            [143, 255, 140], [204, 255, 4], [255, 51, 7], [204, 70, 3],\n",
    "            [0, 102, 200], [61, 230, 250], [255, 6, 51], [11, 102, 255],\n",
    "            [255, 7, 71], [255, 9, 224], [9, 7, 230], [220, 220, 220],\n",
    "            [255, 9, 92], [112, 9, 255], [8, 255, 214], [7, 255, 224],\n",
    "            [255, 184, 6], [10, 255, 71], [255, 41, 10], [7, 255, 255],\n",
    "            [224, 255, 8], [102, 8, 255], [255, 61, 6], [255, 194, 7],\n",
    "            [255, 122, 8], [0, 255, 20], [255, 8, 41], [255, 5, 153],\n",
    "            [6, 51, 255], [235, 12, 255], [160, 150, 20], [0, 163, 255],\n",
    "            [140, 140, 140], [250, 10, 15], [20, 255, 0], [31, 255, 0],\n",
    "            [255, 31, 0], [255, 224, 0], [153, 255, 0], [0, 0, 255],\n",
    "            [255, 71, 0], [0, 235, 255], [0, 173, 255], [31, 0, 255],\n",
    "            [11, 200, 200], [255, 82, 0], [0, 255, 245], [0, 61, 255],\n",
    "            [0, 255, 112], [0, 255, 133], [255, 0, 0], [255, 163, 0],\n",
    "            [255, 102, 0], [194, 255, 0], [0, 143, 255], [51, 255, 0],\n",
    "            [0, 82, 255], [0, 255, 41], [0, 255, 173], [10, 0, 255],\n",
    "            [173, 255, 0], [0, 255, 153], [255, 92, 0], [255, 0, 255],\n",
    "            [255, 0, 245], [255, 0, 102], [255, 173, 0], [255, 0, 20],\n",
    "            [255, 184, 184], [0, 31, 255], [0, 255, 61], [0, 71, 255],\n",
    "            [255, 0, 204], [0, 255, 194], [0, 255, 82], [0, 10, 255],\n",
    "            [0, 112, 255], [51, 0, 255], [0, 194, 255], [0, 122, 255],\n",
    "            [0, 255, 163], [255, 153, 0], [0, 255, 10], [255, 112, 0],\n",
    "            [143, 255, 0], [82, 0, 255], [163, 255, 0], [255, 235, 0],\n",
    "            [8, 184, 170], [133, 0, 255], [0, 255, 92], [184, 0, 255],\n",
    "            [255, 0, 31], [0, 184, 255], [0, 214, 255], [255, 0, 112],\n",
    "            [92, 255, 0], [0, 224, 255], [112, 224, 255], [70, 184, 160],\n",
    "            [163, 0, 255], [153, 0, 255], [71, 255, 0], [255, 0, 163],\n",
    "            [255, 204, 0], [255, 0, 143], [0, 255, 235], [133, 255, 0],\n",
    "            [255, 0, 235], [245, 0, 255], [255, 0, 122], [255, 245, 0],\n",
    "            [10, 190, 212], [214, 255, 0], [0, 204, 255], [20, 0, 255],\n",
    "            [255, 255, 0], [0, 153, 255], [0, 41, 255], [0, 255, 204],\n",
    "            [41, 0, 255], [41, 255, 0], [173, 0, 255], [0, 245, 255],\n",
    "            [71, 0, 255], [122, 0, 255], [0, 255, 184], [0, 92, 255],\n",
    "            [184, 255, 0], [0, 133, 255], [255, 214, 0], [25, 194, 194],\n",
    "            [102, 255, 0], [92, 0, 255]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b0c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First, rescale logits to original image size\n",
    "upsampled_logits = nn.functional.interpolate(logits,\n",
    "                size=image.size[::-1], # (height, width)\n",
    "                mode='bilinear',\n",
    "                align_corners=False)\n",
    "\n",
    "# Second, apply argmax on the class dimension\n",
    "seg = upsampled_logits.argmax(dim=1)[0]\n",
    "color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8) # height, width, 3\n",
    "palette = np.array(ade_palette())\n",
    "for label, color in enumerate(palette):\n",
    "    color_seg[seg == label, :] = color\n",
    "# Convert to BGR\n",
    "color_seg = color_seg[..., ::-1]\n",
    "\n",
    "# Show image + mask\n",
    "img = np.array(image) * 0.5 + color_seg * 0.5\n",
    "img = img.astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956096e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "map = Image.open('/content/ADE20k_toy_dataset/annotations/training/ADE_train_00000001.png') \n",
    "map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f3270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert map to NumPy array\n",
    "map = np.array(map)\n",
    "map[map == 0] = 255 # background class is replaced by ignore_index\n",
    "map = map - 1 # other classes are reduced by one\n",
    "map[map == 254] = 255\n",
    "\n",
    "classes_map = np.unique(map).tolist()\n",
    "unique_classes = [model.config.id2label[idx] if idx!=255 else None for idx in classes_map]\n",
    "print(\"Classes in this image:\", unique_classes)\n",
    "\n",
    "# create coloured map\n",
    "color_seg = np.zeros((map.shape[0], map.shape[1], 3), dtype=np.uint8) # height, width, 3\n",
    "palette = np.array(ade_palette())\n",
    "for label, color in enumerate(palette):\n",
    "    color_seg[map == label, :] = color\n",
    "# Convert to BGR\n",
    "color_seg = color_seg[..., ::-1]\n",
    "\n",
    "# Show image + mask\n",
    "img = np.array(image) * 0.5 + color_seg * 0.5\n",
    "img = img.astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5b7ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec53837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
