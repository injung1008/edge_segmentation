{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2484f5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_indices ['data/b.jpg', None]\n",
      "mean_bgr: [103.939, 116.779, 123.68]\n",
      "output_dir: result/BRIND2CLASSIC\n",
      "Restoring weights from: checkpoints/BRIND/11/11_model.pth\n",
      "************ image_path data/b.jpg\n",
      "actual size: (1852, 3408, 3), target size: (512, 512)\n",
      "['b.png']: torch.Size([1, 3, 512, 512])\n",
      "-------------------------------------------------------\n",
      "[[255 255 255 ...   0   0   0]\n",
      " [255 255 255 ...   0   0   0]\n",
      " [255 255 255 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]\n",
      " [  0   0   0 ... 255 255 255]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import time, platform\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from thop import profile\n",
    "\n",
    "from dataset import DATASET_NAMES, BipedDataset, dataset_info\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from modelB4 import LDC\n",
    "\n",
    "\n",
    "IS_LINUX = True if platform.system()==\"Linux\" else False\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data_root,\n",
    "                 test_data,\n",
    "                 mean_bgr,\n",
    "                 img_height,\n",
    "                 img_width,\n",
    "                 test_list=None,\n",
    "                 arg=None\n",
    "                 ):\n",
    "\n",
    "\n",
    "        self.data_root = data_root\n",
    "        self.test_data = test_data\n",
    "        self.test_list = test_list\n",
    "\n",
    "        self.mean_bgr = mean_bgr\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.data_index = self._build_index()\n",
    "\n",
    "        print(f\"mean_bgr: {self.mean_bgr}\")\n",
    "\n",
    "    def _build_index(self):\n",
    "        sample_indices = []\n",
    "        if self.test_data == \"CLASSIC\":\n",
    "            # for single image testing\n",
    "#             images_path = os.listdir(self.data_root)\n",
    "            images_path = self.data_root\n",
    "            labels_path = None\n",
    "            sample_indices = [images_path, labels_path]\n",
    "            print('sample_indices',sample_indices)\n",
    "       \n",
    "        return sample_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1 if self.test_data.upper() == 'CLASSIC' else len(self.data_index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get data sample\n",
    "        # image_path, label_path = self.data_index[idx]\n",
    "        if self.data_index[1] is None:\n",
    "            image_path = self.data_index[0] if len(self.data_index[0]) > 1 else self.data_index[0]\n",
    "            print(f'************ image_path {image_path}')\n",
    "        else:\n",
    "            image_path = self.data_index[idx][0]\n",
    "        label_path = None if self.test_data == \"CLASSIC\" else self.data_index[idx][1]\n",
    "#         img_name = os.path.basename(image_path)\n",
    "#         file_name = os.path.splitext(img_name)[0] + \".png\"\n",
    "        img_name = self.data_root.split('/')\n",
    "        img_name = img_name[-1]\n",
    "        file_name = os.path.splitext(img_name)[0] + \".png\"\n",
    "        \n",
    "\n",
    "\n",
    "        gt_dir = None\n",
    "\n",
    "\n",
    "        image = cv2.imread(self.data_root, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if not self.test_data == \"CLASSIC\":\n",
    "            label = cv2.imread(os.path.join(\n",
    "                gt_dir, label_path), cv2.IMREAD_COLOR)\n",
    "        else:\n",
    "            label = None\n",
    "        \n",
    "        im_shape = [image.shape[0], image.shape[1]]\n",
    "        image, label = self.transform(img=image, gt=label)\n",
    "\n",
    "        return dict(images=image, labels=label, file_names=file_name, image_shape=im_shape)\n",
    "\n",
    "    def transform(self, img, gt):\n",
    "        # gt[gt< 51] = 0 # test without gt discrimination\n",
    "        if self.test_data == \"CLASSIC\":\n",
    "            img_height = self.img_height\n",
    "            img_width = self.img_width\n",
    "            print(\n",
    "                f\"actual size: {img.shape}, target size: {(img_height, img_width,)}\")\n",
    "            # img = cv2.resize(img, (self.img_width, self.img_height))\n",
    "            img = cv2.resize(img, (img_width, img_height))\n",
    "            gt = None\n",
    "\n",
    "        # Make images and labels at least 512 by 512\n",
    "        elif img.shape[0] < 512 or img.shape[1] < 512:\n",
    "            img = cv2.resize(img, (self.img_width, self.img_height))  # 512\n",
    "            gt = cv2.resize(gt, (self.img_width, self.img_height))  # 512\n",
    "\n",
    "        # Make sure images and labels are divisible by 2^4=16\n",
    "        elif img.shape[0] % 16 != 0 or img.shape[1] % 16 != 0:\n",
    "            img_width = ((img.shape[1] // 16) + 1) * 16\n",
    "            img_height = ((img.shape[0] // 16) + 1) * 16\n",
    "            img = cv2.resize(img, (img_width, img_height))\n",
    "            gt = cv2.resize(gt, (img_width, img_height))\n",
    "        else:\n",
    "            img_width = self.img_width\n",
    "            img_height = self.img_height\n",
    "            img = cv2.resize(img, (img_width, img_height))\n",
    "            gt = cv2.resize(gt, (img_width, img_height))\n",
    "        # # For FPS\n",
    "        # img = cv2.resize(img, (496,320))\n",
    "        # if self.yita is not None:\n",
    "        #     gt[gt >= self.yita] = 1\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        # if self.rgb:\n",
    "        #     img = img[:, :, ::-1]  # RGB->BGR\n",
    "        img -= self.mean_bgr\n",
    "        img = img.transpose((2, 0, 1))\n",
    "        img = torch.from_numpy(img.copy()).float()\n",
    "\n",
    "        if self.test_data == \"CLASSIC\":\n",
    "            gt = np.zeros((img.shape[:2]))\n",
    "            gt = torch.from_numpy(np.array([gt])).float()\n",
    "        else:\n",
    "            gt = np.array(gt, dtype=np.float32)\n",
    "            if len(gt.shape) == 3:\n",
    "                gt = gt[:, :, 0]\n",
    "            gt /= 255.\n",
    "            gt = torch.from_numpy(np.array([gt])).float()\n",
    "\n",
    "        return img, gt\n",
    "\n",
    "def image_normalization(img, img_min=0, img_max=255,\n",
    "                        epsilon=1e-12):\n",
    "    \"\"\"This is a typical image normalization function\n",
    "    where the minimum and maximum of the image is needed\n",
    "    source: https://en.wikipedia.org/wiki/Normalization_(image_processing)\n",
    "\n",
    "    :param img: an image could be gray scale or color\n",
    "    :param img_min:  for default is 0\n",
    "    :param img_max: for default is 255\n",
    "\n",
    "    :return: a normalized image, if max is 255 the dtype is uint8\n",
    "    \"\"\"\n",
    "\n",
    "    img = np.float32(img)\n",
    "    # whenever an inconsistent image\n",
    "    img = (img - np.min(img)) * (img_max - img_min) / \\\n",
    "        ((np.max(img) - np.min(img)) + epsilon) + img_min\n",
    "    return img\n",
    "\n",
    "def save_image_batch_to_disk(tensor, output_dir, file_names, img_shape=None,  is_inchannel=False):\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    is_testing = True\n",
    "   \n",
    "\n",
    "    fuse_name = 'fused'\n",
    "    av_name = 'avg'\n",
    "    tensor2=None\n",
    "    tmp_img2 = None\n",
    "\n",
    "    output_dir_f = os.path.join(output_dir, fuse_name)\n",
    "    output_dir_a = os.path.join(output_dir, av_name)\n",
    "    os.makedirs(output_dir_f, exist_ok=True)\n",
    "    os.makedirs(output_dir_a, exist_ok=True)\n",
    "\n",
    "    # 255.0 * (1.0 - em_a)\n",
    "    edge_maps = []\n",
    "    for i in tensor:\n",
    "        tmp = torch.sigmoid(i).cpu().detach().numpy()\n",
    "        edge_maps.append(tmp)\n",
    "    tensor = np.array(edge_maps)\n",
    "    # print(f\"tensor shape: {tensor.shape}\")\n",
    "\n",
    "    image_shape = [x.cpu().detach().numpy() for x in img_shape]\n",
    "    # (H, W) -> (W, H)\n",
    "    image_shape = [[y, x] for x, y in zip(image_shape[0], image_shape[1])]\n",
    "\n",
    "    assert len(image_shape) == len(file_names)\n",
    "\n",
    "    idx = 0\n",
    "    for i_shape, file_name in zip(image_shape, file_names):\n",
    "        tmp = tensor[:, idx, ...]\n",
    "        tmp2 = tensor2[:, idx, ...] if tensor2 is not None else None\n",
    "        # tmp = np.transpose(np.squeeze(tmp), [0, 1, 2])\n",
    "        tmp = np.squeeze(tmp)\n",
    "        tmp2 = np.squeeze(tmp2) if tensor2 is not None else None\n",
    "\n",
    "        # Iterate our all 7 NN outputs for a particular image\n",
    "        preds = []\n",
    "        fuse_num = tmp.shape[0]-1\n",
    "        for i in range(tmp.shape[0]):\n",
    "            tmp_img = tmp[i]\n",
    "            tmp_img = np.uint8(image_normalization(tmp_img))\n",
    "            tmp_img = cv2.bitwise_not(tmp_img)\n",
    "            # tmp_img[tmp_img < 0.0] = 0.0\n",
    "            # tmp_img = 255.0 * (1.0 - tmp_img)\n",
    "            if tmp2 is not None:\n",
    "                tmp_img2 = tmp2[i]\n",
    "                tmp_img2 = np.uint8(image_normalization(tmp_img2))\n",
    "                tmp_img2 = cv2.bitwise_not(tmp_img2)\n",
    "\n",
    "            # Resize prediction to match input image size\n",
    "            if not tmp_img.shape[1] == i_shape[0] or not tmp_img.shape[0] == i_shape[1]:\n",
    "                tmp_img = cv2.resize(tmp_img, (i_shape[0], i_shape[1]))\n",
    "                tmp_img2 = cv2.resize(tmp_img2, (i_shape[0], i_shape[1])) if tmp2 is not None else None\n",
    "\n",
    "\n",
    "            if tmp2 is not None:\n",
    "                tmp_mask = np.logical_and(tmp_img>128,tmp_img2<128)\n",
    "                tmp_img= np.where(tmp_mask, tmp_img2, tmp_img)\n",
    "                preds.append(tmp_img)\n",
    "\n",
    "            else:\n",
    "                preds.append(tmp_img)\n",
    "\n",
    "            if i == fuse_num:\n",
    "                # print('fuse num',tmp.shape[0], fuse_num, i)\n",
    "                fuse = tmp_img\n",
    "                fuse = fuse.astype(np.uint8)\n",
    "                if tmp_img2 is not None:\n",
    "                    fuse2 = tmp_img2\n",
    "                    fuse2 = fuse2.astype(np.uint8)\n",
    "                    # fuse = fuse-fuse2\n",
    "                    fuse_mask=np.logical_and(fuse>128,fuse2<128)\n",
    "                    fuse = np.where(fuse_mask,fuse2, fuse)\n",
    "\n",
    "                    # print(fuse.shape, fuse_mask.shape)\n",
    "\n",
    "        # Get the mean prediction of all the 7 outputs\n",
    "        average = np.array(preds, dtype=np.float32)\n",
    "        average = np.uint8(np.mean(average, axis=0))\n",
    "        output_file_name_f = os.path.join(output_dir_f, file_name)\n",
    "        output_file_name_a = os.path.join(output_dir_a, file_name)\n",
    "\n",
    "        fuse[fuse >= 200] = 255\n",
    "        fuse[fuse < 200] = 0\n",
    "        \n",
    "        cv2.imwrite(output_file_name_f, fuse)\n",
    "        cv2.imwrite(output_file_name_a, average)\n",
    "\n",
    "        idx += 1\n",
    "        return fuse, average\n",
    "\n",
    "def test(checkpoint_path, dataloader, model, device, output_dir):\n",
    "    if not os.path.isfile(checkpoint_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Checkpoint filte note found: {checkpoint_path}\")\n",
    "    print(f\"Restoring weights from: {checkpoint_path}\")\n",
    "    model.load_state_dict(torch.load(checkpoint_path,\n",
    "                                     map_location=device))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_id, sample_batched in enumerate(dataloader):\n",
    "            images = sample_batched['images'].to(device)\n",
    "\n",
    "            file_names = sample_batched['file_names']\n",
    "\n",
    "            image_shape = sample_batched['image_shape']\n",
    "\n",
    "            print(f\"{file_names}: {images.shape}\")\n",
    "\n",
    "            end = time.perf_counter()\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "            preds = model(images)\n",
    "\n",
    "\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "            fuse, average = save_image_batch_to_disk(preds,\n",
    "                                     output_dir,\n",
    "                                     file_names,\n",
    "                                     image_shape)\n",
    "            torch.cuda.empty_cache()\n",
    "    return fuse, average\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(img_path):\n",
    "    \"\"\"Main function.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    checkpoint_path = 'checkpoints/BRIND/11/11_model.pth'\n",
    "\n",
    "\n",
    "    device = torch.device('cpu' if torch.cuda.device_count() == 0\n",
    "                          else 'cuda')\n",
    "\n",
    "    # Instantiate model and move it to the computing device\n",
    "    model = LDC().to(device)\n",
    "\n",
    "\n",
    "\n",
    "    TEST_DATA = 'CLASSIC'\n",
    "\n",
    "    test_inf = dataset_info(TEST_DATA, is_linux=IS_LINUX)\n",
    "\n",
    "    # test_inf {'img_height': 512, 'img_width': 512, 'test_list': None, 'train_list': None, 'data_dir': 'data', 'yita': 0.5}\n",
    "    \n",
    "    test_dir = test_inf['data_dir']\n",
    "    input_val_dir = img_path\n",
    "    test_list = test_inf['test_list']\n",
    "    test_img_width = test_inf['img_width']\n",
    "    test_img_height = test_inf['img_height']\n",
    "    mean_pixel_values = [103.939,116.779,123.68,137.86]    \n",
    "    workers = 8\n",
    "    \n",
    "    dataset_val = TestDataset(input_val_dir,\n",
    "                              test_data=TEST_DATA,\n",
    "                              img_width=test_img_width,\n",
    "                              img_height=test_img_height,\n",
    "                              mean_bgr=mean_pixel_values[0:3] if len(\n",
    "                                  mean_pixel_values) == 4 else mean_pixel_values,\n",
    "                              test_list=test_list\n",
    "                              )\n",
    "    dataloader_val = DataLoader(dataset_val,\n",
    "                                batch_size=1,\n",
    "                                shuffle=False,\n",
    "                                num_workers=workers)\n",
    "\n",
    "\n",
    "    output_dir = 'result/BRIND2CLASSIC'\n",
    "\n",
    "    fuse, average = test(checkpoint_path, dataloader_val, model, device, output_dir)\n",
    "\n",
    "\n",
    "    print('-------------------------------------------------------')\n",
    "    \n",
    "    return fuse, average\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    img_path = 'data/b.jpg'\n",
    "    fuse, average = main(img_path)\n",
    "    print(fuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00756464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a.jpg', 'b.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "img_path = 'data'\n",
    "file_list = os.listdir(img_path)\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbfa5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f5996d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hihi\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class test(Dataset) : \n",
    "    def __init__(self):\n",
    "        self.data_idx = 1 \n",
    "    def __len__(self) :\n",
    "        print('dd')\n",
    "        return 2 \n",
    "    def __getitem__(self, idx):\n",
    "        print(idx)\n",
    "    def hi(self):\n",
    "        print('hihi')\n",
    "t = test()    \n",
    "t.hi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d352ea90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
